{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â ‹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â ™ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â ¹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â ¸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â ¼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â ´ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â ¦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff: 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5: 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051: 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Generation**: Generative AI can be used to generate high-quality content such as articles, social media posts, product descriptions, and more. This can save time and resources for businesses that need to produce large amounts of content.\n",
      "2. **Product Design and Prototyping**: Generative AI can help designers create new products, shapes, and designs by generating 3D models, prototypes, and even entire product lines.\n",
      "3. **Marketing and Advertising**: Generative AI can be used to generate personalized marketing messages, social media ads, and email campaigns that are tailored to individual customers.\n",
      "4. **Customer Service and Support**: Generative AI-powered chatbots can provide 24/7 customer support, helping to answer common questions and route more complex issues to human representatives.\n",
      "5. **Data Analysis and Insights**: Generative AI can be used to analyze large datasets, identify patterns, and generate insights that help businesses make data-driven decisions.\n",
      "6. **Predictive Maintenance**: Generative AI can be used to predict equipment failures, reducing downtime and increasing overall efficiency in industries such as manufacturing, energy, and transportation.\n",
      "7. **Image and Video Generation**: Generative AI can be used to create new images, videos, and graphics for marketing, advertising, and entertainment purposes.\n",
      "8. **Speech Synthesis**: Generative AI can be used to generate realistic speech syntheses for voice assistants, audiobooks, and other applications.\n",
      "9. **Natural Language Processing (NLP)**: Generative AI can be used to improve language translation, text summarization, and sentiment analysis, among other NLP tasks.\n",
      "10. **Business Process Automation**: Generative AI can be used to automate business processes such as bookkeeping, accounting, and order processing.\n",
      "\n",
      "Some specific use cases for generative AI include:\n",
      "\n",
      "* **Virtual product demonstrations**: Using generative AI to create realistic 3D models of products that can be demonstrated on a website or in-store.\n",
      "* **Personalized marketing messages**: Using generative AI to generate personalized marketing messages based on customer data and behavior.\n",
      "* **Automated content creation**: Using generative AI to automate the creation of high-quality content such as blog posts, social media updates, and product descriptions.\n",
      "* **Predictive maintenance for industrial equipment**: Using generative AI to predict when industrial equipment is likely to fail, allowing for proactive maintenance and reducing downtime.\n",
      "\n",
      "These are just a few examples of the many business applications of generative AI. As the technology continues to evolve, we can expect to see even more innovative uses across various industries.\n"
     ]
    }
   ],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI (Artificial Intelligence) has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Generation**: AI-powered tools can generate high-quality content such as articles, blog posts, social media posts, and product descriptions, saving time and effort for human writers.\n",
      "2. **Virtual Assistants**: Generative AI can power virtual assistants like chatbots, voice assistants, and customer service chatbots, enabling businesses to provide 24/7 support and improve customer experience.\n",
      "3. **Personalization**: Generative AI can help personalize products, services, and marketing campaigns by analyzing customer data and behavior, leading to increased engagement and conversion rates.\n",
      "4. **Image and Video Generation**: AI-powered tools can create high-quality images and videos for various applications such as product design, advertising, and entertainment.\n",
      "5. **Predictive Maintenance**: Generative AI can analyze sensor data from machines and predict when maintenance is required, reducing downtime and improving overall efficiency.\n",
      "6. **Recommendation Systems**: AI-powered recommendation engines can suggest products or services to customers based on their behavior and preferences, driving sales and revenue growth.\n",
      "7. **Automated Translations**: Generative AI can power automated translation tools, enabling businesses to communicate with global customers more effectively and expand their market reach.\n",
      "8. **Marketing Automation**: Generative AI can automate marketing tasks such as email campaigns, lead generation, and social media management, freeing up resources for strategic decision-making.\n",
      "9. **Creative Collaboration**: AI-powered tools can facilitate collaborative creative projects by suggesting ideas, generating content, and automating tedious tasks, enabling artists, designers, and writers to focus on high-level creativity.\n",
      "10. **Supply Chain Optimization**: Generative AI can analyze supply chain data and predict demand, enabling businesses to optimize inventory management, reduce waste, and improve delivery times.\n",
      "\n",
      "Some specific industries that are leveraging Generative AI include:\n",
      "\n",
      "1. **E-commerce**: Using AI-powered tools to generate product descriptions, optimize product listings, and personalize customer experiences.\n",
      "2. **Finance**: Using AI-powered chatbots to provide 24/7 customer support, automate risk management, and predict creditworthiness.\n",
      "3. **Healthcare**: Using AI-powered tools to analyze medical data, predict patient outcomes, and develop personalized treatment plans.\n",
      "4. **Education**: Using AI-powered tools to create customized learning materials, personalize student experiences, and grade assignments.\n",
      "5. **Manufacturing**: Using AI-powered tools to optimize production processes, predict equipment failures, and improve product quality.\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative uses across various industries.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, transforming the way companies operate, interact with customers, and innovate. Here are some examples:\n",
      "\n",
      "1. **Content Creation**: Generative AI can generate high-quality content such as blog posts, social media posts, product descriptions, and more, saving time and effort for content teams.\n",
      "2. **Product Design and Development**: Generative designers can create 3D models, prototypes, and product designs more efficiently than human designers. This is particularly useful in industries like automotive, aerospace, and consumer electronics.\n",
      "3. **Marketing Automation**: Generative AI-powered chatbots can engage with customers, provide personalized experiences, and automate marketing campaigns, such as email and social media outreach.\n",
      "4. **Customer Service and Support**: Generative AI-powered chatbots and virtual assistants can help resolve common customer inquiries, freeing human support agents to focus on more complex issues.\n",
      "5. **Predictive Analytics and Forecasting**: Generative AI models can analyze historical data and make predictions about future trends, sales, revenue, and other business outcomes, enabling data-driven decision-making.\n",
      "6. **Personalized Recommendations**: Generative AI algorithms can create tailored product recommendations based on user behavior, preferences, and purchase history, enhancing the overall customer experience.\n",
      "7. **Supply Chain Optimization**: Generative AI models can analyze supply chain dynamics, predict demand fluctuations, and suggest optimal inventory levels and shipping routes to minimize costs.\n",
      "8. **Financial Analysis and Predictive Modeling**: Generative AI algorithms can analyze vast amounts of financial data, identifying patterns, making predictions about future market trends, and providing insights for informed investment decisions.\n",
      "9. **Natural Language Processing (NLP) and Text Analysis**: Generative AI models can parse complex text, sentiment analysis, and topic modeling, helping companies understand customer sentiment, brand reputation, and social media discourse.\n",
      "10. **Designing Virtual Reality experiences**: Generative AI algorithms create immersive virtual world designs which are especially useful in industries like gaming, entertainment, film, and more.\n",
      "\n",
      "To fully capitalize on the business potential of Generative AI, it's essential to:\n",
      "\n",
      "* Identify specific business needs and opportunities where generative capabilities can provide value.\n",
      "* Develop relevant data sets and integrate them with existing infrastructure to facilitate generative workflows.\n",
      "* Train experts in Generative AI frameworks, languages, and tools to implement and fine-tune models effectively.\n",
      "\n",
      "As the field of Generative AI continues to evolve, new applications and business uses will emerge.\n"
     ]
    }
   ],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e22da-b891-41f6-9ac9-bd0c0a5f4f44",
   "metadata": {},
   "source": [
    "## Are you confused about why that works?\n",
    "\n",
    "It seems strange, right? We just used OpenAI code to call Ollama?? What's going on?!\n",
    "\n",
    "Here's the scoop:\n",
    "\n",
    "The python class `OpenAI` is simply code written by OpenAI engineers that makes calls over the internet to an endpoint.  \n",
    "\n",
    "When you call `openai.chat.completions.create()`, this python code just makes a web request to the following url: \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "Code like this is known as a \"client library\" - it's just wrapper code that runs on your machine to make web requests. The actual power of GPT is running on OpenAI's cloud behind this API, not on your computer!\n",
    "\n",
    "OpenAI was so popular, that lots of other AI providers provided identical web endpoints, so you could use the same approach.\n",
    "\n",
    "So Ollama has an endpoint running on your local box at http://localhost:11434/v1/chat/completions  \n",
    "And in week 2 we'll discover that lots of other providers do this too, including Gemini and DeepSeek.\n",
    "\n",
    "And then the team at OpenAI had a great idea: they can extend their client library so you can specify a different 'base url', and use their library to call any compatible API.\n",
    "\n",
    "That's it!\n",
    "\n",
    "So when you say: `ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')`  \n",
    "Then this will make the same endpoint calls, but to Ollama instead of OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## Also trying the amazing reasoning model DeepSeek\n",
    "\n",
    "Here we use the version of DeepSeek-reasoner that's been distilled to 1.5B.  \n",
    "This is actually a 1.5B variant of Qwen that has been fine-tuned using synethic data generated by Deepseek R1.\n",
    "\n",
    "Other sizes of DeepSeek are [here](https://ollama.com/library/deepseek-r1) all the way up to the full 671B parameter version, which would use up 404GB of your drive and is far too large for most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â ‹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â ™ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â ¹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling aabd4debf0c8: 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 1.1 GB                         \u001b[K\n",
      "pulling 369ca498f347: 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�  387 B                         \u001b[K\n",
      "pulling 6e4c38e1172f: 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 1.1 KB                         \u001b[K\n",
      "pulling f4d24e9138dd: 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�  148 B                         \u001b[K\n",
      "pulling a85fe2a2e58e: 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�  487 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to figure out the definitions for some core concepts related to Large Language Models (LLMs), specifically focusing on neural networks, attention mechanisms, and transformers. Hmm, let me try to break this down step by step.\n",
      "\n",
      "Starting with neural networks—uh, right! I remember from my classes that LLMs use something called a neural network. But wait, which type? Oh yeah, probably something called the Transformer model or another kind of RNN. Also, maybe some kind of neural architecture. The user mentioned neural network as the core concept, so maybe I should stick to that.\n",
      "\n",
      "Now, attention comes into play too. What's attention again? Well, I think it has something to do with how models focus on specific parts of input data. So like assigning weights or probabilities. It must not just be about time series predictions and word embeddings because those are already covered under the core definitions I need for LLMs.\n",
      "\n",
      "Wait, but isn't attention more common in methods like transformers or language models? And how does it relate to neural networks? Oh, right! The Transformer architecture includes a key-value memory attention mechanism. So that's probably what's referred to as attention and the transformer. But if the question is specifically about the core concepts behind LLMs, maybe just defining attention in that specific context would be better.\n",
      "\n",
      "And then there's the neural network itself—does that include all kinds of layers or something more specialized? I'm a bit confused because different models might use various types of networks. For instance, attention mechanisms are part of the decoder-only RNN architecture, while other models like CNNs might use fully convolutional layers in image recognition tasks.\n",
      "\n",
      "So perhaps the core neural network concept is the foundation that underpins these LLM structures. But specifically for LLMs, which parts involve attention and transformers? I think the Transformer architecture with its self-attention mechanism is central to it.\n",
      "\n",
      "Also, considering all of this, maybe the question is trying to build a bridge between more traditional deep learning concepts (like CNNs) and the newer RNN/BPE-like approaches. So understanding each layer's role in LLM models can help connect different approaches from time series analysis through to language modeling.\n",
      "\n",
      "I'm a bit shaky on how exactly attention and transformers tie into the overall structure of neural networks within LLMs. Wait, maybe I should think about each component:\n",
      "\n",
      "1. Neural Network: As the general term, but specific to LLMs this refers to models made up of layers like Transformers.\n",
      "\n",
      "2. Attention mechanisms in LLMs: Focus on how the model attends to different parts of input data or previous tokens.\n",
      "\n",
      "3. Transformers specifically: A layer-based architecture with self-attention for processing sequences.\n",
      "\n",
      "So putting it all together, perhaps each core concept (neural network, attention, transformer) is a building block that contributes in specific ways to LLMs. But when the user asks for definitions, I should probably start by defining each term individually before explaining their role within LLMs.\n",
      "\n",
      "Maybe that's overcomplicating things, since definitions are usually concise, but ensuring clarity on terms.\n",
      "\n",
      "I'm also wondering if there are other non-neural network concepts relevant to LLMs—maybe something to do with embeddings or optimization techniques—but the user specified focusing on neural networks, attention, and transformers. So I'll stick to those.\n",
      "\n",
      "In summary, I think the initial steps should be:\n",
      "\n",
      "1. Define what a Neural Network is in the context of LLMs.\n",
      "2. Define Attention mechanisms within this framework.\n",
      "3. Explain how Transformers exemplify a specific type of Neural Network architecture.\n",
      "4. Possibly provide an example using the Transformer for clarity.\n",
      "\n",
      "I need to make sure each definition is clear and concise, without jargon-heavy explanations unless necessary.\n",
      "</think>\n",
      "\n",
      "To address the core concepts behind Large Language Models (LLMs), focusing on neural networks, attention mechanisms, and transformers, here's a structured explanation:\n",
      "\n",
      "### 1. Neural Network in LLMs\n",
      "A Neural Network within LLMs primarily serves as the foundational structure that processes input data to generate outputs. \n",
      "- **Functionality**: Encapsulates layers optimized through backpropagation for learning hierarchical patterns in data.\n",
      "- **Types**: Beyond traditional RNNs, these utilize architectures like Transformers with self-attention mechanisms.\n",
      "\n",
      "### 2. Attention Mechanisms within LLMs\n",
      "Attention in LLMs enables the model to focus on relevant parts of input or previous tokens.\n",
      "- **Focus**: Assignes weights to specific inputs, crucial for understanding context and relevance.\n",
      "- **Application**: Often part of decoder-only architectures where each token's attention score influences others.\n",
      "\n",
      "### 3. Transformers as a Neural Network\n",
      "Transformers exemplify an Neural Network architecture with self-attention:\n",
      "- **Self-Correlation in RNNs**: Unlike traditional time series models, transformers use self-attention for sequential data.\n",
      "- **Layer Structure**: Contains multiple layers optimized through backpropagation to extract deep contextual patterns.\n",
      "\n",
      "### 4. Example: Transformer Architecture\n",
      "The Transformer architecture uses a decoder-only RNN with:\n",
      "- **Self-Attention Layers**: Capture relationships between all input tokens.\n",
      "- **Position-Wise Feed-Forward**: Enhances feature representation through multi-head attention and attention-based projections.\n",
      "- **Efficiency**: Breaks reliance on recurrent layers, focusing solely on sequential data.\n",
      "\n",
      "### Conclusion\n",
      "These components—_neural network_, _attention_, and _transformers_ form the backbone of LLMs, bridging traditional deep learning and innovative RNN/BPE approaches.\n"
     ]
    }
   ],
   "source": [
    "# This may take a few minutes to run! You should then see a fascinating \"thinking\" trace inside <think> tags, followed by some decent definitions\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a4e92bb-3b04-46d4-99fa-15c2927bd207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b8f3f73-330c-4d7a-9ed2-3668e5a7631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1b815f7-2ae9-4c43-b362-1eb956eb69a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "\n",
    "class Website:\n",
    "    \"\"\"\n",
    "    A utility class to represent a Website that we have scraped\n",
    "    \"\"\"\n",
    "    url: str\n",
    "    title: str\n",
    "    text: str\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad589613-198d-46e3-9e0a-9e41a06148f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home - Edward Donner\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Well, hi there.\n",
      "I’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\n",
      "very\n",
      "amateur) and losing myself in\n",
      "Hacker News\n",
      ", nodding my head sagely to things I only half understand.\n",
      "I’m the co-founder and CTO of\n",
      "Nebula.io\n",
      ". We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\n",
      "acquired in 2021\n",
      ".\n",
      "We work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\n",
      "patented\n",
      "our matching model, and our award-winning platform has happy customers and tons of press coverage.\n",
      "Connect\n",
      "with me for more!\n",
      "April 21, 2025\n",
      "The Complete Agentic AI Engineering Course\n",
      "January 23, 2025\n",
      "LLM Workshop – Hands-on with Agents – resources\n",
      "December 21, 2024\n",
      "Welcome, SuperDataScientists!\n",
      "November 13, 2024\n",
      "Mastering AI and LLM Engineering – Resources\n",
      "Navigation\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Get in touch\n",
      "ed [at] edwarddonner [dot] com\n",
      "www.edwarddonner.com\n",
      "Follow me\n",
      "LinkedIn\n",
      "Twitter\n",
      "Facebook\n",
      "Subscribe to newsletter\n",
      "Type your email…\n",
      "Subscribe\n"
     ]
    }
   ],
   "source": [
    "# Let's try one out\n",
    "\n",
    "ed = Website(\"https://edwarddonner.com\")\n",
    "print(ed.title)\n",
    "print(ed.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d431475c-4a32-4eb8-b65b-c62bc548495a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our system prompt - you can experiment with this later, changing the last sentence to 'Respond in markdown in Spanish.\"\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d266af24-9f3e-45a9-8ac7-8ef72ec4b1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how this function creates exactly the format above\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a6dbe3a-58ab-471d-a8ee-9c1b89269df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that writes a User Prompt that asks for summaries of websites:\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"The contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "770ec3a0-445a-4bae-a14c-15f9c0091a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now: call the Ollama function instead of OpenAI\n",
    "\n",
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    messages = messages_for(website)\n",
    "    response = ollama.chat(model=MODEL, messages=messages)\n",
    "    return response['message']['content']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "733fcd5e-51c6-4b37-b73b-244a0c9e3818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Website Summary\\n\\n### Overview\\nThe website is owned by Edward Donner, a co-founder and CTO of Nebula.io. The platform applies AI to help people discover their potential and pursue their reason for being.\\n\\n### Latest News/Announcements\\n- **April 21, 2025**: Release of \"The Complete Agentic AI Engineering Course\"\\n- **January 23, 2025**: LLM Workshop – Hands-on with Agents – resources\\n- **December 21, 2024**: Welcome message to SuperDataScientists\\n- **November 13, 2024**: Mastering AI and LLM Engineering – Resources\\n\\n### Content Areas\\nThe website features three main content areas:\\n\\n*   Connect Four: A game or arena where LLMs compete against each other.\\n*   Outsmart: An arena that pits LLMs against each other in a battle of diplomacy and deviousness.\\n*   About: Edward Donner\\'s personal story, including his work at Nebula.io and untapt.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63f16721-a3f2-44a9-8c75-9614fed0294d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to display this nicely in the Jupyter output, using markdown\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "941ec866-de2d-4e48-ae0c-9be42220d861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Summary of the Website**\n",
       "==========================\n",
       "\n",
       "### About the Author and Company\n",
       "\n",
       "The website is owned by Edward Donner, a co-founder and CTO of Nebula.io. He is also the founder and former CEO of AI startup untapt, acquired in 2021.\n",
       "\n",
       "### Recent Announcements and News\n",
       "---------------------------\n",
       "\n",
       "* **New Course:** The Complete Agentic AI Engineering Course was announced on April 21, 2025.\n",
       "* **Upcoming Workshop:** LLM Workshop – Hands-on with Agents – resources was scheduled for December 21, 2024.\n",
       "* **Welcome Message:** A welcome message for SuperDataScientists was shared in November 2024.\n",
       "\n",
       "### Focus Areas\n",
       "\n",
       "The website appears to focus on:\n",
       "\n",
       "* Artificial Intelligence (AI) and Large Language Models (LLMs)\n",
       "* Talent acquisition and management using AI\n",
       "* Education and training resources for AI and LLM engineering\n",
       "\n",
       "Note that the website also mentions other topics, such as DJing and hacker culture, but these appear to be personal interests rather than a primary focus of the site."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "65adeee1-b934-46b4-81b2-726298740682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here's a summary of the top news stories from CNN:\n",
       "\n",
       "1. **Pope Leo XIV Elected**: The Catholic Church has elected Pope Leo XIV, an American-born pope who is expected to bring significant changes to the church's leadership and policies.\n",
       "2. **Iran Talks Collapse**: The US and Iran have failed to reach a deal in talks aimed at resolving the conflict between the two countries, with no new negotiations scheduled for Sunday.\n",
       "3. **New York City Plane Crash**: A small plane crashed into the East River in New York City, killing all 11 people on board.\n",
       "4. **US Measles Outbreak**: The US has reported a significant increase in measles cases, with thousands of people infected across the country.\n",
       "5. **California Wildfires**: Wildfires continue to burn in California, forcing thousands of people to evacuate their homes and causing widespread damage.\n",
       "6. **Supreme Court Justice David Souter Dies**: Supreme Court Justice David Souter, a Bush nominee who veered to the left on several key issues, has died at the age of 85.\n",
       "7. **Tariffs and Stock Market Volatility**: The ongoing trade war between the US and China continues to cause volatility in the stock market, with tariffs and trade tensions continuing to impact businesses and investors.\n",
       "8. **Global Airlines A380 Launch**: Global Airlines has launched its new A380 superjumbo aircraft, but the launch has been met with controversy due to concerns about the environmental impact of the large planes.\n",
       "\n",
       "These are just a few of the top news stories from CNN. For more information on these and other news stories, visit [www.cnn.com](http://www.cnn.com)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://cnn.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a3699a6-beb2-49ee-847c-a831527388de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Summary of BBC Home Website**\n",
       "\n",
       "### News\n",
       "\n",
       "* Pope Leo XIV's first days as pope have sparked scrutiny about his leadership style and potential impact on the Catholic Church.\n",
       "* The US and China are set to hold trade talks in Geneva, Switzerland.\n",
       "* India and Pakistan have accused each other of firing missiles at airbases.\n",
       "* A woman who allegedly was the head of the Catholic Church has become one of the most controversial medieval tales.\n",
       "\n",
       "### Culture\n",
       "\n",
       "* Eurovision 2025: Guide to all 37 songs and artists participating in the contest.\n",
       "* Fifty Shades director James Foley dies aged 71.\n",
       "* The overlooked masterpiece full of coded messages about WW1.\n",
       "* Rediscovered Thomas & Friends pilot to be released.\n",
       "\n",
       "### Business\n",
       "\n",
       "* Hormone-treated beef will not enter UK after US deal, says government.\n",
       "* Trump proposes 80% China tariff ahead of trade talks.\n",
       "* NHS plans 'unthinkable' cuts to balance books.\n",
       "\n",
       "### Technology\n",
       "\n",
       "* Bill Gates plans to give away most of his fortune by 2045.\n",
       "* Apple hits back at US judge's 'extraordinary' contempt order.\n",
       "* Space debris is a looming crisis.\n",
       "\n",
       "### Science & Environment\n",
       "\n",
       "* Scientists reveal 'remarkable' wasp memory.\n",
       "* Moon dust 'rarer than gold' arrives in UK from China.\n",
       "* The secrets of feeding the papal conclave.\n",
       "\n",
       "### Earth\n",
       "\n",
       "* Daring langurs cross over busy roadway in Malaysia.\n",
       "* How a park ranger alerted world to Sycamore Gap tree's fate.\n",
       "\n",
       "### Video\n",
       "\n",
       "* The secret WW2 magazine ridiculing Hitler's mother.\n",
       "* Watch how rare sperm is found in IVF lab."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://bbc.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d35302-8cc1-451b-a0b3-1b43cc9d218b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
